# -*- coding: utf-8 -*-
"""
Created on Sat Nov 14 16:09:17 2015

@author: phil
"""
import os
import numpy as np
import p_utils
import sys
import timeit
lib_path = os.path.abspath(os.path.join('DeepLearningTutorials'))
sys.path.append(lib_path)
from utils import tile_raster_images
from RTC_dA import RTC_dA
import theano
import theano.tensor as T
from theano.tensor.shared_randomstreams import RandomStreams


try:
    import PIL.Image as Image
except ImportError:
    import Image
    
def test_dA(learning_rate=0.1, training_epochs=50,
            dataset='mnist.pkl.gz',
            batch_size=20, output_folder='dA_plots',
            corruption_level = 50,nHidden = 1):


    stim, resp = p_utils.getStrfData('pSimple')
    
    stim= p_utils.normalize(stim,featureMin= 0,featureMax= 1)
    
    train_set_x  = p_utils.load_shared_data(stim)
        
    
    resp = np.log(1+resp)
    resp = resp.astype('float')
    train_set_y = p_utils.load_shared_data(resp)

    
    # compute number of minibatches for training, validation and testing
    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size
    
    train_set_x = T.cast(train_set_x, 'float32')
    train_set_y = T.cast(train_set_y, 'float32')
    # start-snippet-2
    # allocate symbolic variables for the data
    index = T.lscalar()    # index to a [mini]batch
    x = T.matrix('x')  # the data is presented as rasterized images
    y = T.vector('y')
    # end-snippet-2

    if not os.path.isdir(output_folder):
        os.makedirs(output_folder)
    os.chdir(output_folder)
    

    nRowsCols = np.floor(np.sqrt(nHidden)).astype('int')
    

    rng = np.random.RandomState(123)
    theano_rng = RandomStreams(rng.randint(2 ** 30))


    da = RTC_dA(
        numpy_rng=rng,
        theano_rng=theano_rng,
        input=x,
        resp=y,
        n_visible=30 * 30,
        n_hidden=nHidden,
        activation = 'sigmoid'
    )

    cost, updates = da.get_cost_updates(
        corruption_level=float(corruption_level)/100.0,
        learning_rate=learning_rate,
        errorFunc = 'crossEntropy'
    )

    train_da = theano.function(
        [index],
        cost,
        updates=updates,
        givens={
            x: train_set_x[index * batch_size: (index + 1) * batch_size],
            y:train_set_y[index * batch_size: (index + 1) * batch_size]
        }
    )

    start_time = timeit.default_timer()

    ############
    # TRAINING #
    ############

    # go through training epochs
    for epoch in xrange(training_epochs):
        # go through trainng set
        c = []
        for batch_index in xrange(n_train_batches):
            c.append(train_da(batch_index))

        print 'Training epoch %d, cost ' % epoch, np.mean(c)

    end_time = timeit.default_timer()

    training_time = (end_time - start_time)

    print >> sys.stderr, ('The 50% corruption code for file ' +
                          os.path.split(__file__)[1] +
                          ' ran for %.2fm' % (training_time / 60.))
    # end-snippet-3

    # start-snippet-4
    imageName = 'filters_corruption_' + str(corruption_level) + '.png'
    image = Image.fromarray(tile_raster_images(
        X=da.W.get_value(borrow=True).T,
        img_shape=(30, 30), tile_shape=(nRowsCols, nRowsCols),
        tile_spacing=(1, 1)))
        
    image.save(imageName)

    os.chdir('../')
    
    
    
    
def main():
    test_dA()

    

if __name__ == '__main__':
    main()