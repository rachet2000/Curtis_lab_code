#1. Import tensorflow and the MNIST dataset
import tensorflow as tf
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
tf.reset_default_graph()

#2. Start an interacive session
sess = tf.InteractiveSession()

#3. Initialize the x and y predicted variables.
x = tf.placeholder(tf.float32, shape = [None, 28, 28, 1])
y_ = tf.placeholder(tf.float32, shape = [None, 10])

max_epochs = 1000

#4. Initialize the weight matrix and the bias matrix as variables
w1 = tf.Variable(tf.truncated_normal([5,5,1,32], stddev = 0.1))
w2 = tf.Variable(tf.truncated_normal([5,5,32,64], stddev = 0.1))
b1 = tf.Variable(tf.constant(0.1, shape = [32]))
b2 = tf.Variable(tf.constant(0.1, shape = [64]))



#6. Define the function; how the variables relate to x and y
conv1 = tf.nn.relu(tf.nn.conv2d(x, w1, strides = [1,1,1,1], padding = 'SAME') + b1)
pool1 = tf.nn.max_pool(conv1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')
conv2 = tf.nn.relu(tf.nn.conv2d(pool1, w2, strides = [1,1,1,1], padding = 'SAME') + b2)
pool2 = tf.nn.max_pool(conv2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')


wd1 = tf.Variable(tf.truncated_normal([7*7*64, 1024], stddev = 0.1))
bd1 = tf.Variable(tf.constant(0.1, shape = [1024]))

pool2_flat = tf.reshape(pool2, [-1, 7*7*64])
y1 = tf.nn.relu(tf.matmul(pool2_flat, wd1) + bd1)

keep_prob = tf.placeholder(tf.float32)
y1_drop = tf.nn.dropout(y1, keep_prob)

wd2 = tf.Variable(tf.truncated_normal([1024, 10], stddev = 0.1))
bd2 = tf.Variable(tf.constant(0.1, shape = [10]))
y2 = tf.nn.softmax(tf.matmul(y1_drop,wd2) + bd2)

#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y2), reduction_indices = [1]))
cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y2))
training = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)

correct_prediction = tf.equal(tf.argmax(y2,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

sess.run(tf.global_variables_initializer())

#Train the model. Builds on 8
for i in range(max_epochs):
  #sess.run(training, feed_dict = {x: mnist.train.images, y_: mnist.train.labels})
  batch = mnist.train.next_batch(50)
  x_data = np.reshape(batch[0], [-1, 28, 28, 1])
  x_test = np.reshape(mnist.test.images, [-1, 28, 28, 1])
  
  #sess.run(training, feed_dict={x: batch[0], y_: batch[1]})
  training.run(feed_dict = {x:x_data, y_:batch[1], keep_prob:0.5})
  if i%10 == 0:
      print(i, sess.run(accuracy, feed_dict = {x:x_data, y_:batch[1], keep_prob:1})) # sess.run(accuracy, feed_dict = {x:x_test, y_:mnist.test.labels, keep_prob:1}))


#9. Check whether the model was correct

#print(accuracy.eval(feed_dict={x: mnist.train.images, y_: mnist.train.labels}))
#print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))